{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Search Engine</th>\n",
       "      <th>Destination Searched</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>Google</td>\n",
       "      <td>Florida</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>Baidu</td>\n",
       "      <td>Xian</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>French</td>\n",
       "      <td>Google</td>\n",
       "      <td>Paris</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>French</td>\n",
       "      <td>Google</td>\n",
       "      <td>Montreal</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English</td>\n",
       "      <td>Google</td>\n",
       "      <td>Florida</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language Search Engine Destination Searched   Label\n",
       "0  English        Google              Florida      US\n",
       "1  English         Baidu                 Xian   China\n",
       "2   French        Google                Paris  France\n",
       "3   French        Google             Montreal  Canada\n",
       "4  English        Google              Florida      US"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from IPython.display import display\n",
    "\n",
    "# Load the sessions dataset\n",
    "data = pd.read_csv(\"Example test.csv\")\n",
    "\n",
    "# Display the first record\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into features and target label\n",
    "label_raw = data['Label']\n",
    "features_raw = data.drop('Label', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 total features after one-hot encoding.\n",
      "['Language_English', 'Language_French', 'Search Engine_Baidu', 'Search Engine_Google', 'Destination Searched_Florida', 'Destination Searched_Montreal', 'Destination Searched_Paris', 'Destination Searched_Xian']\n"
     ]
    }
   ],
   "source": [
    "# TODO: One-hot encode the 'features_log_minmax_transform' data using pandas.get_dummies()\n",
    "features_final = pd.get_dummies(features_raw)\n",
    "\n",
    "# TODO: Encode the 'income_raw' data to numerical values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le= LabelEncoder()\n",
    "le.fit(label_raw)\n",
    "label = le.transform(label_raw)\n",
    "\n",
    "# Print the number of features after one-hot encoding\n",
    "encoded = list(features_final.columns)\n",
    "print (\"{} total features after one-hot encoding.\".format(len(encoded)))\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 79 samples.\n",
      "Testing set has 20 samples.\n",
      "    Language_English  Language_French  Search Engine_Baidu  \\\n",
      "43                 0                1                    0   \n",
      "62                 1                0                    0   \n",
      "3                  0                1                    0   \n",
      "71                 1                0                    1   \n",
      "45                 1                0                    1   \n",
      "\n",
      "    Search Engine_Google  Destination Searched_Florida  \\\n",
      "43                     1                             0   \n",
      "62                     1                             1   \n",
      "3                      1                             0   \n",
      "71                     0                             0   \n",
      "45                     0                             0   \n",
      "\n",
      "    Destination Searched_Montreal  Destination Searched_Paris  \\\n",
      "43                              1                           0   \n",
      "62                              0                           0   \n",
      "3                               1                           0   \n",
      "71                              0                           0   \n",
      "45                              0                           0   \n",
      "\n",
      "    Destination Searched_Xian  \n",
      "43                          0  \n",
      "62                          0  \n",
      "3                           0  \n",
      "71                          1  \n",
      "45                          1  \n",
      "[0 3 0 1 1 3 2 0 2 3 2 3 1 0 3 0 2 2 1 1 1 0 2 1 3 0 1 3 2 1 2 1 3 2 3 2 0\n",
      " 0 0 1 2 0 1 0 0 1 3 3 2 3 0 1 1 1 2 0 3 1 2 1 1 1 1 3 0 3 3 3 3 0 3 1 0 1\n",
      " 3 2 2 1 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Split the 'features' and 'income' data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_final, \n",
    "                                                    label, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)\n",
    "\n",
    "# Show the results of the split\n",
    "print (\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print (\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
    "print(X_train.head())\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Language_English  Language_French  Search Engine_Baidu  \\\n",
      "26                 0                1                    0   \n",
      "86                 0                1                    0   \n",
      "2                  0                1                    0   \n",
      "55                 1                0                    1   \n",
      "75                 0                1                    0   \n",
      "\n",
      "    Search Engine_Google  Destination Searched_Florida  \\\n",
      "26                     1                             0   \n",
      "86                     1                             0   \n",
      "2                      1                             0   \n",
      "55                     0                             0   \n",
      "75                     1                             0   \n",
      "\n",
      "    Destination Searched_Montreal  Destination Searched_Paris  \\\n",
      "26                              0                           1   \n",
      "86                              0                           1   \n",
      "2                               0                           1   \n",
      "55                              0                           0   \n",
      "75                              0                           1   \n",
      "\n",
      "    Destination Searched_Xian  \n",
      "26                          0  \n",
      "86                          0  \n",
      "2                           0  \n",
      "55                          1  \n",
      "75                          0  \n",
      "[array([[ 0.,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0.,  1.],\n",
      "       [ 0.,  0.,  0.,  1.],\n",
      "       [ 0.,  0.,  0.,  1.],\n",
      "       [ 0.,  0.,  0.,  1.],\n",
      "       [ 1.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.],\n",
      "       [ 1.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.],\n",
      "       [ 1.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0.,  1.],\n",
      "       [ 0.,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  1.]]), array([[ 0.,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0.,  1.],\n",
      "       [ 0.,  0.,  0.,  1.],\n",
      "       [ 0.,  0.,  0.,  1.],\n",
      "       [ 0.,  0.,  0.,  1.],\n",
      "       [ 1.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.],\n",
      "       [ 1.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.],\n",
      "       [ 1.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0.,  1.],\n",
      "       [ 0.,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  1.]])]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "#X_train, y_train = make_classification(n_samples=79, n_features=8, n_informative=5, n_classes=4, random_state=1)\n",
    "y2 = y_train\n",
    "Y = np.vstack((y_train, y2)).T\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=10, random_state=1)\n",
    "multi_target_forest = MultiOutputClassifier(forest, n_jobs=-1)\n",
    "multi_target_forest.fit(X_train, Y).predict(X_train)\n",
    "\n",
    "print(X_test.head())\n",
    "print(multi_target_forest.predict_proba(X_test))\n",
    "#print(Y)\n",
    "#for first_array in multi_target_forest.predict_proba(X_train):\n",
    "#    for second_array in first_array:\n",
    "#        sorted_array = sorted(second_array, reverse=True)\n",
    "#        print(sorted_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 1 2 3 3 3 3 0 2 0 2 1 0 2 2 3 1 3]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 1 2 3 3 3 3 0 2 0 2 1 0 2 2 3 1 3]\n"
     ]
    }
   ],
   "source": [
    "y_array =np.asarray(y_test)\n",
    "\n",
    "print(y_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 1, 0], [0, 0, 1, 0], [0, 0, 1, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 0, 0, 0], [0, 0, 1, 0], [1, 0, 0, 0], [0, 0, 1, 0], [0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 1, 0], [0, 0, 0, 1], [0, 1, 0, 0], [0, 0, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "array_to_compare_predictions=[]\n",
    "nested_array=[]\n",
    "for element in y_array:\n",
    "    i=0\n",
    "    nested_array=[]\n",
    "    while i < 4:\n",
    "        if i == element:\n",
    "            nested_array.append(1)\n",
    "            i=i+1\n",
    "        else:\n",
    "            nested_array.append(0)\n",
    "            i=i+1\n",
    "    array_to_compare_predictions.append(nested_array)\n",
    "        \n",
    "print(array_to_compare_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Array_to_compare_predictions =np.asarray(array_to_compare_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(array_to_compare_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20L, 4L)\n"
     ]
    }
   ],
   "source": [
    "print(Array_to_compare_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [0 1 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]\n",
      " [0 1 0 0]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(Array_to_compare_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20L, 4L)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_target_forest.predict_proba(X_test)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(multi_target_forest.predict_proba(X_test)[0][19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  1.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(multi_target_forest.predict_proba(X_test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_values = Array_to_compare_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = multi_target_forest.predict_proba(X_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1, 2, 4, 3], dtype=int64), array([1, 2, 4, 3], dtype=int64), array([1, 2, 4, 3], dtype=int64), array([1, 4, 2, 3], dtype=int64), array([1, 2, 4, 3], dtype=int64), array([1, 2, 3, 4], dtype=int64), array([1, 2, 3, 4], dtype=int64), array([1, 2, 3, 4], dtype=int64), array([1, 2, 3, 4], dtype=int64), array([4, 1, 2, 3], dtype=int64), array([1, 2, 4, 3], dtype=int64), array([4, 1, 2, 3], dtype=int64), array([1, 2, 4, 3], dtype=int64), array([1, 4, 2, 3], dtype=int64), array([4, 1, 2, 3], dtype=int64), array([1, 2, 4, 3], dtype=int64), array([1, 2, 4, 3], dtype=int64), array([1, 2, 3, 4], dtype=int64), array([1, 4, 2, 3], dtype=int64), array([1, 2, 3, 4], dtype=int64)]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/6422700/how-to-get-indices-of-a-sorted-array-in-python\n",
    "#https://stackoverflow.com/questions/6193498/pythonic-way-to-find-maximum-value-and-its-index-in-a-list\n",
    "#https://stackoverflow.com/questions/5284646/rank-items-in-an-array-using-python-numpy\n",
    "\n",
    "import operator\n",
    "\n",
    "maximal_value_tracking_index =[]\n",
    "\n",
    "for element in predictions:\n",
    "    order = element.argsort()\n",
    "    rank = order.argsort()\n",
    " #   rank = rank +1\n",
    " #   sorted_rank=sorted(rank, reverse=True)\n",
    "    maximal_value_tracking_index.append(rank+1)\n",
    "\n",
    "print(maximal_value_tracking_index)\n",
    "print(order)\n",
    "print(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximal_value_tracking_index = np.asarray(maximal_value_tracking_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_spelled_out = ['CA', 'CN', 'FR', 'US'] #these labels are consistent with the predictions and true. one hot encoding puts the countries in descending order. Apply sort, in case any countries out of order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sort_label_spelled_out = sorted(label_spelled_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_labels = np.tile(np.asarray(sort_label_spelled_out), (20,1)) #create an array with the same shape as the training set, #https://stackoverflow.com/questions/1550130/cloning-row-or-column-vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['CA', 'CN', 'FR', 'US'],\n",
       "       ['CA', 'CN', 'FR', 'US'],\n",
       "       ['CA', 'CN', 'FR', 'US'],\n",
       "       ['CA', 'CN', 'FR', 'US'],\n",
       "       ['CA', 'CN', 'FR', 'US'],\n",
       "       ['CA', 'CN', 'FR', 'US'],\n",
       "       ['CA', 'CN', 'FR', 'US'],\n",
       "       ['CA', 'CN', 'FR', 'US'],\n",
       "       ['CA', 'CN', 'FR', 'US'],\n",
       "       ['CA', 'CN', 'FR', 'US'],\n",
       "       ['CA', 'CN', 'FR', 'US'],\n",
       "       ['CA', 'CN', 'FR', 'US'],\n",
       "       ['CA', 'CN', 'FR', 'US'],\n",
       "       ['CA', 'CN', 'FR', 'US'],\n",
       "       ['CA', 'CN', 'FR', 'US'],\n",
       "       ['CA', 'CN', 'FR', 'US'],\n",
       "       ['CA', 'CN', 'FR', 'US'],\n",
       "       ['CA', 'CN', 'FR', 'US'],\n",
       "       ['CA', 'CN', 'FR', 'US'],\n",
       "       ['CA', 'CN', 'FR', 'US']],\n",
       "      dtype='|S2')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each element, in each array, assign country_labels with the value in maximal value tracking. Remember, 4 is the largest and considerd the country most likely to vist\n",
    "# https://stackoverflow.com/questions/6618515/sorting-list-based-on-values-from-another-list\n",
    "\n",
    "i=0\n",
    "country_labels_maximal_tracking = []\n",
    "for element in country_labels:\n",
    "    country_labels_maximal_tracking.append(zip(maximal_value_tracking_index[i],country_labels[i]))\n",
    "    i=i+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(1, 'CA'), (2, 'CN'), (4, 'FR'), (3, 'US')],\n",
       " [(1, 'CA'), (2, 'CN'), (4, 'FR'), (3, 'US')],\n",
       " [(1, 'CA'), (2, 'CN'), (4, 'FR'), (3, 'US')],\n",
       " [(1, 'CA'), (4, 'CN'), (2, 'FR'), (3, 'US')],\n",
       " [(1, 'CA'), (2, 'CN'), (4, 'FR'), (3, 'US')],\n",
       " [(1, 'CA'), (2, 'CN'), (3, 'FR'), (4, 'US')],\n",
       " [(1, 'CA'), (2, 'CN'), (3, 'FR'), (4, 'US')],\n",
       " [(1, 'CA'), (2, 'CN'), (3, 'FR'), (4, 'US')],\n",
       " [(1, 'CA'), (2, 'CN'), (3, 'FR'), (4, 'US')],\n",
       " [(4, 'CA'), (1, 'CN'), (2, 'FR'), (3, 'US')],\n",
       " [(1, 'CA'), (2, 'CN'), (4, 'FR'), (3, 'US')],\n",
       " [(4, 'CA'), (1, 'CN'), (2, 'FR'), (3, 'US')],\n",
       " [(1, 'CA'), (2, 'CN'), (4, 'FR'), (3, 'US')],\n",
       " [(1, 'CA'), (4, 'CN'), (2, 'FR'), (3, 'US')],\n",
       " [(4, 'CA'), (1, 'CN'), (2, 'FR'), (3, 'US')],\n",
       " [(1, 'CA'), (2, 'CN'), (4, 'FR'), (3, 'US')],\n",
       " [(1, 'CA'), (2, 'CN'), (4, 'FR'), (3, 'US')],\n",
       " [(1, 'CA'), (2, 'CN'), (3, 'FR'), (4, 'US')],\n",
       " [(1, 'CA'), (4, 'CN'), (2, 'FR'), (3, 'US')],\n",
       " [(1, 'CA'), (2, 'CN'), (3, 'FR'), (4, 'US')]]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_labels_maximal_tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sort the labels in reverse order\n",
    "for element in country_labels_maximal_tracking:\n",
    "    element.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(4, 'FR'), (3, 'US'), (2, 'CN'), (1, 'CA')],\n",
       " [(4, 'FR'), (3, 'US'), (2, 'CN'), (1, 'CA')],\n",
       " [(4, 'FR'), (3, 'US'), (2, 'CN'), (1, 'CA')],\n",
       " [(4, 'CN'), (3, 'US'), (2, 'FR'), (1, 'CA')],\n",
       " [(4, 'FR'), (3, 'US'), (2, 'CN'), (1, 'CA')],\n",
       " [(4, 'US'), (3, 'FR'), (2, 'CN'), (1, 'CA')],\n",
       " [(4, 'US'), (3, 'FR'), (2, 'CN'), (1, 'CA')],\n",
       " [(4, 'US'), (3, 'FR'), (2, 'CN'), (1, 'CA')],\n",
       " [(4, 'US'), (3, 'FR'), (2, 'CN'), (1, 'CA')],\n",
       " [(4, 'CA'), (3, 'US'), (2, 'FR'), (1, 'CN')],\n",
       " [(4, 'FR'), (3, 'US'), (2, 'CN'), (1, 'CA')],\n",
       " [(4, 'CA'), (3, 'US'), (2, 'FR'), (1, 'CN')],\n",
       " [(4, 'FR'), (3, 'US'), (2, 'CN'), (1, 'CA')],\n",
       " [(4, 'CN'), (3, 'US'), (2, 'FR'), (1, 'CA')],\n",
       " [(4, 'CA'), (3, 'US'), (2, 'FR'), (1, 'CN')],\n",
       " [(4, 'FR'), (3, 'US'), (2, 'CN'), (1, 'CA')],\n",
       " [(4, 'FR'), (3, 'US'), (2, 'CN'), (1, 'CA')],\n",
       " [(4, 'US'), (3, 'FR'), (2, 'CN'), (1, 'CA')],\n",
       " [(4, 'CN'), (3, 'US'), (2, 'FR'), (1, 'CA')],\n",
       " [(4, 'US'), (3, 'FR'), (2, 'CN'), (1, 'CA')]]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_labels_maximal_tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the country from each subarray in country_labels_maximal_tracking\n",
    "country_labels_sorted =[]\n",
    "for element in country_labels_maximal_tracking:\n",
    "    tracking_array = []\n",
    "    i=0\n",
    "    for sub_element in element:  \n",
    "        if i<2:                                     #keep the first 5 elements in each subarray   \n",
    "            tracking_array.append(sub_element[1])\n",
    "            i=i+1\n",
    "        else:\n",
    "            None\n",
    "    country_labels_sorted.append(tracking_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['FR', 'US'],\n",
       " ['FR', 'US'],\n",
       " ['FR', 'US'],\n",
       " ['CN', 'US'],\n",
       " ['FR', 'US'],\n",
       " ['US', 'FR'],\n",
       " ['US', 'FR'],\n",
       " ['US', 'FR'],\n",
       " ['US', 'FR'],\n",
       " ['CA', 'US'],\n",
       " ['FR', 'US'],\n",
       " ['CA', 'US'],\n",
       " ['FR', 'US'],\n",
       " ['CN', 'US'],\n",
       " ['CA', 'US'],\n",
       " ['FR', 'US'],\n",
       " ['FR', 'US'],\n",
       " ['US', 'FR'],\n",
       " ['CN', 'US'],\n",
       " ['US', 'FR']]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_labels_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/6422700/how-to-get-indices-of-a-sorted-array-in-python\n",
    "#https://stackoverflow.com/questions/6193498/pythonic-way-to-find-maximum-value-and-its-index-in-a-list\n",
    "\n",
    "#index_of_reranking_predictions =[]\n",
    "#for element in predictions:\n",
    "#    index_of_reranking_predictions.append([i[0] for i in sorted(enumerate(element), key=lambda x:x[1])])\n",
    "\n",
    "#print(index_of_reranking_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "index_for_DCG =[]\n",
    "\n",
    "i=0\n",
    "for rank_element in maximal_value_tracking_index:\n",
    "    if rank_element[y_test[i]] == 4: #maximal probability\n",
    "        index_for_DCG.append(1)\n",
    "    else:\n",
    "        if rank_element[y_test[i]] == 1:  #1 is a special number to mean that both the prediction and true value matches at the last position.\n",
    "            index_for_DCG.append(4)\n",
    "        else:\n",
    "            index_for_DCG.append(rank_element[y_test[i]])        \n",
    "    i=i+1\n",
    "\n",
    "print(index_for_DCG)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_nDCG(x):\n",
    "    nDCG = [] \n",
    "    for element in x:\n",
    "        nDCG.append((2 - 1)/math.log(element+1, 2))\n",
    "    return nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19, 0, 0, 0], [19, 0, 0, 0], [19, 0, 0, 0], [19, 0, 0, 0], [19, 0, 0, 0], [19, 0, 0, 0], [19, 0, 0, 0], [19, 0, 0, 0], [19, 0, 0, 0], [19, 0, 0, 0], [19, 0, 0, 0], [19, 0, 0, 0], [19, 0, 0, 0], [19, 0, 0, 0], [19, 0, 0, 0], [19, 0, 0, 0], [19, 0, 0, 0], [19, 0, 0, 0], [19, 0, 0, 0], [19, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "a_list = [1,0,0,0]\n",
    "another_list = []\n",
    "\n",
    "for i in range(20):\n",
    "    another_list.append(a_list)\n",
    "    a_list[0] = i + 0\n",
    "\n",
    "print(another_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([4, 1, 2, 3], dtype=int64), array([4, 1, 2, 3], dtype=int64), array([4, 1, 2, 3], dtype=int64), array([4, 1, 2, 3], dtype=int64), array([4, 1, 2, 3], dtype=int64), array([4, 1, 2, 3], dtype=int64), array([4, 1, 2, 3], dtype=int64), array([4, 1, 2, 3], dtype=int64), array([4, 1, 2, 3], dtype=int64), array([4, 1, 2, 3], dtype=int64), array([4, 1, 2, 3], dtype=int64), array([4, 1, 2, 3], dtype=int64), array([4, 1, 2, 3], dtype=int64), array([4, 1, 2, 3], dtype=int64), array([4, 1, 2, 3], dtype=int64), array([4, 1, 2, 3], dtype=int64), array([4, 1, 2, 3], dtype=int64), array([4, 1, 2, 3], dtype=int64), array([4, 1, 2, 3], dtype=int64), array([4, 1, 2, 3], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "maximal_value_tracking_index_dummy =[]\n",
    "another_list_to_array = np.array(another_list)\n",
    "\n",
    "for element in another_list_to_array:\n",
    "    order = element.argsort()\n",
    "    rank = order.argsort()\n",
    "    maximal_value_tracking_index_dummy.append(rank+1)\n",
    "\n",
    "print(maximal_value_tracking_index_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 4, 2, 3, 3, 3, 3, 1, 2, 1, 2, 4, 1, 2, 2, 3, 4, 3]\n"
     ]
    }
   ],
   "source": [
    "index_for_DCG_dummy =[]\n",
    "\n",
    "i=0\n",
    "for rank_element in maximal_value_tracking_index_dummy:\n",
    "    if rank_element[y_test[i]] == 4:\n",
    "        index_for_DCG_dummy.append(1)\n",
    "    else:\n",
    "        if rank_element[y_test[i]] == 1:\n",
    "            index_for_DCG_dummy.append(4)\n",
    "        else:\n",
    "            index_for_DCG_dummy.append(rank_element[y_test[i]])\n",
    "    i=i+1\n",
    "  \n",
    "print(index_for_DCG_dummy)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2L, 2L, 2L, 1L, 2L, 3L, 3L, 3L, 3L, 0L, 2L, 0L, 2L, 1L, 0L, 2L, 2L, 3L, 1L, 3L]\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray((y_test)).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6309297535714574,\n",
       " 0.6309297535714574,\n",
       " 0.6309297535714574,\n",
       " 0.43067655807339306,\n",
       " 0.6309297535714574,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 1.0,\n",
       " 0.6309297535714574,\n",
       " 1.0,\n",
       " 0.6309297535714574,\n",
       " 0.43067655807339306,\n",
       " 1.0,\n",
       " 0.6309297535714574,\n",
       " 0.6309297535714574,\n",
       " 0.5,\n",
       " 0.43067655807339306,\n",
       " 0.5]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_nDCG(index_for_DCG_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the sessions dataset\n",
    "sessions_data = pd.read_csv(\"sessions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>action</th>\n",
       "      <th>action_type</th>\n",
       "      <th>action_detail</th>\n",
       "      <th>device_type</th>\n",
       "      <th>secs_elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>lookup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>search_results</td>\n",
       "      <td>click</td>\n",
       "      <td>view_search_results</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>67753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>lookup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>301.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>search_results</td>\n",
       "      <td>click</td>\n",
       "      <td>view_search_results</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>22141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>lookup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>435.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id          action action_type        action_detail  \\\n",
       "0  d1mm9tcy42          lookup         NaN                  NaN   \n",
       "1  d1mm9tcy42  search_results       click  view_search_results   \n",
       "2  d1mm9tcy42          lookup         NaN                  NaN   \n",
       "3  d1mm9tcy42  search_results       click  view_search_results   \n",
       "4  d1mm9tcy42          lookup         NaN                  NaN   \n",
       "\n",
       "       device_type  secs_elapsed  \n",
       "0  Windows Desktop         319.0  \n",
       "1  Windows Desktop       67753.0  \n",
       "2  Windows Desktop         301.0  \n",
       "3  Windows Desktop       22141.0  \n",
       "4  Windows Desktop         435.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first record\n",
    "display(sessions_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sessions_data['action_type'] = sessions_data['action_type'].fillna('action_type_missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>action</th>\n",
       "      <th>action_type</th>\n",
       "      <th>action_detail</th>\n",
       "      <th>device_type</th>\n",
       "      <th>secs_elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>lookup</td>\n",
       "      <td>action_type_missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>search_results</td>\n",
       "      <td>click</td>\n",
       "      <td>view_search_results</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>67753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>lookup</td>\n",
       "      <td>action_type_missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>301.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>search_results</td>\n",
       "      <td>click</td>\n",
       "      <td>view_search_results</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>22141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>lookup</td>\n",
       "      <td>action_type_missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>435.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id          action          action_type        action_detail  \\\n",
       "0  d1mm9tcy42          lookup  action_type_missing                  NaN   \n",
       "1  d1mm9tcy42  search_results                click  view_search_results   \n",
       "2  d1mm9tcy42          lookup  action_type_missing                  NaN   \n",
       "3  d1mm9tcy42  search_results                click  view_search_results   \n",
       "4  d1mm9tcy42          lookup  action_type_missing                  NaN   \n",
       "\n",
       "       device_type  secs_elapsed  \n",
       "0  Windows Desktop         319.0  \n",
       "1  Windows Desktop       67753.0  \n",
       "2  Windows Desktop         301.0  \n",
       "3  Windows Desktop       22141.0  \n",
       "4  Windows Desktop         435.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sessions_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sessions_data['action'] = sessions_data['action'].fillna('action_missing')\n",
    "\n",
    "sessions_data['action_detail'] = sessions_data['action_detail'].fillna('action_detail_missing')\n",
    "\n",
    "sessions_data['device_type'] = sessions_data['device_type'].fillna('device_type_missing')\n",
    "\n",
    "sessions_data['secs_elapsed'] = sessions_data['secs_elapsed'].fillna(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3563"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions_data['user_id'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1048575, 6)\n"
     ]
    }
   ],
   "source": [
    "print(sessions_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sessions_data_removed_blank_id = sessions_data[pd.notnull(sessions_data['user_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>action</th>\n",
       "      <th>action_type</th>\n",
       "      <th>action_detail</th>\n",
       "      <th>device_type</th>\n",
       "      <th>secs_elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>lookup</td>\n",
       "      <td>action_type_missing</td>\n",
       "      <td>action_detail_missing</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>search_results</td>\n",
       "      <td>click</td>\n",
       "      <td>view_search_results</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>67753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>lookup</td>\n",
       "      <td>action_type_missing</td>\n",
       "      <td>action_detail_missing</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>301.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>search_results</td>\n",
       "      <td>click</td>\n",
       "      <td>view_search_results</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>22141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>lookup</td>\n",
       "      <td>action_type_missing</td>\n",
       "      <td>action_detail_missing</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>435.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id          action          action_type          action_detail  \\\n",
       "0  d1mm9tcy42          lookup  action_type_missing  action_detail_missing   \n",
       "1  d1mm9tcy42  search_results                click    view_search_results   \n",
       "2  d1mm9tcy42          lookup  action_type_missing  action_detail_missing   \n",
       "3  d1mm9tcy42  search_results                click    view_search_results   \n",
       "4  d1mm9tcy42          lookup  action_type_missing  action_detail_missing   \n",
       "\n",
       "       device_type  secs_elapsed  \n",
       "0  Windows Desktop         319.0  \n",
       "1  Windows Desktop       67753.0  \n",
       "2  Windows Desktop         301.0  \n",
       "3  Windows Desktop       22141.0  \n",
       "4  Windows Desktop         435.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sessions_data_removed_blank_id.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1045012, 6)\n"
     ]
    }
   ],
   "source": [
    "print(sessions_data_removed_blank_id.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userid_unique_values= sessions_data_removed_blank_id.user_id.unique() \n",
    "\n",
    "action_unique_values_bf = (sessions_data_removed_blank_id.action.unique()).reshape(244,1) #before flattened\n",
    "\n",
    "action_type_unique_values_bf = (sessions_data_removed_blank_id.action_type.unique()).reshape(10,1) #before flattened\n",
    "\n",
    "action_detail_unique_values_bf = sessions_data_removed_blank_id.action_detail.unique().reshape(105,1) #before flattened\n",
    "\n",
    "device_type_bf = sessions_data_removed_blank_id.device_type.unique().reshape(14,1) #before flattened\n",
    "\n",
    "\n",
    "#https://stackoverflow.com/questions/11264684/flatten-list-of-lists\n",
    "\n",
    "action_unique_values = [val for sublist in action_unique_values_bf for val in sublist]\n",
    "\n",
    "action_type_unique_values = [val for sublist in action_type_unique_values_bf for val in sublist]\n",
    "\n",
    "action_detail_unique_values = [val for sublist in action_detail_unique_values_bf for val in sublist]\n",
    "\n",
    "device_type = [val for sublist in device_type_bf for val in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(device_type.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://pbpython.com/pandas-pivot-table-explained.html\n",
    "\n",
    "sessions_data_pivoted = pd.pivot_table(sessions_data_removed_blank_id, index=[\"user_id\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userid_unique_values = sessions_data_removed_blank_id.user_id.unique()\n",
    "\n",
    "#action_unique_values = sessions_data_removed_blank_id.action.unique().reshape(1,244)\n",
    "\n",
    "#action_type_unique_values = sessions_data_removed_blank_id.action_type.unique().reshape(1,10)\n",
    "\n",
    "#action_detail_unique_values = sessions_data_removed_blank_id.action_detail.unique().reshape(1,105)\n",
    "\n",
    "#device_type = sessions_data_removed_blank_id.device_type.unique().reshape(1,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert array to DataFrame\n",
    "\n",
    "action_unique_values_df = pd.DataFrame(columns=sessions_data_removed_blank_id.action.unique().reshape(1,244)[0])\n",
    "\n",
    "action_type_unique_values_df = pd.DataFrame(columns=sessions_data_removed_blank_id.action_type.unique().reshape(1,10)[0])\n",
    "\n",
    "action_detail_unique_values_df = pd.DataFrame(columns=sessions_data_removed_blank_id.action_detail.unique().reshape(1,105)[0])\n",
    "\n",
    "device_type_df = pd.DataFrame(columns=sessions_data_removed_blank_id.device_type.unique().reshape(1,14)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# #https://stackoverflow.com/questions/20995196/python-pandas-counting-and-summing-specific-conditions\n",
    "# #https://stackoverflow.com/questions/10715965/add-one-row-in-a-pandas-dataframe\n",
    "\n",
    "# i=0 #key to action_unique_values\n",
    "# j=1 #key to the ith row in new action_unique_values dataframe\n",
    "\n",
    "\n",
    "# for element in sessions_data_pivoted['user_id']:\n",
    "#     current_user = sessions_data[sessions_data.user_id == element] #filter dataframe for that user_id and assign filtered dataframe to current_user\n",
    "#     for element_action in action_unique_values:\n",
    "#         running_sum = 0\n",
    "#         running_sum = current_user.action[current_user.action == action_unique_values[i]].count() #assign the count of the latest action to running_sum \n",
    "#         i=i+1\n",
    "#         action_unique_values_df.set_value(j, element_action, running_sum) #add the latest count of that action to action_unique_values dataframe\n",
    "#     j=j+1 #reindex so that we move to the next row when it looks at the next user\n",
    "#     i=0 #reindex so that we start at the beginning of action_unique_values when we look at next user\n",
    "#     \n",
    "# writer = pd.ExcelWriter('first_batch_of_action_unique_values.xlsx')\n",
    "# action_unique_values_df.to_excel(writer,'Sheet1')\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# i=0 #key to action_unique_values\n",
    "# j=1 #key to the ith row in new action_unique_values dataframe\n",
    "\n",
    "\n",
    "# for element in sessions_data_pivoted['user_id']:\n",
    "#     current_user = sessions_data[sessions_data.user_id == element] #filter dataframe for that user_id and assign filtered dataframe to current_user\n",
    "#     for element_action in action_type_unique_values:\n",
    "#         running_sum = 0\n",
    "#         running_sum = current_user.action_type[current_user.action_type == action_type_unique_values[i]].count() #assign the count of the latest action to running_sum \n",
    "#         i=i+1\n",
    "#         action_type_unique_values_df.set_value(j, element_action, running_sum) #add the latest count of that action to action_unique_values dataframe\n",
    "#     j=j+1 #reindex so that we move to the next row when it looks at the next user\n",
    "#     i=0 #reindex so that we start at the beginning of action_unique_values when we look at next user\n",
    "    \n",
    "# writer = pd.ExcelWriter('action_type_unique_values2.xlsx')\n",
    "# action_type_unique_values_df.to_excel(writer,'Sheet1')\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# i=0 #key to action_unique_values\n",
    "# j=1 #key to the ith row in new action_unique_values dataframe\n",
    "\n",
    "\n",
    "# for element in sessions_data_pivoted['user_id']:\n",
    "#     current_user = sessions_data[sessions_data.user_id == element] #filter dataframe for that user_id and assign filtered dataframe to current_user\n",
    "#     for element_action in device_type:\n",
    "#         running_sum = 0\n",
    "#         running_sum = current_user.device_type[current_user.device_type == device_type[i]].count() #assign the count of the latest action to running_sum \n",
    "#         i=i+1\n",
    "#         device_type_df.set_value(j, element_action, running_sum) #add the latest count of that action to action_unique_values dataframe\n",
    "#     j=j+1 #reindex so that we move to the next row when it looks at the next user\n",
    "#     i=0 #reindex so that we start at the beginning of action_unique_values when we look at next user\n",
    "    \n",
    "# writer = pd.ExcelWriter('device_type.xlsx')\n",
    "# device_type_df.to_excel(writer,'Sheet1')\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(sessions_data_pivoted)\n",
    "# writer = pd.ExcelWriter('user_id_and_secs_elapsed.xlsx')\n",
    "# sessions_data_pivoted.to_excel(writer,'Sheet1')\n",
    "# writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for element in sessions_data_pivoted['user_id']:\n",
    "#     print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #action_detail_unique_values\n",
    "\n",
    "# i=0 #key to action_unique_values\n",
    "# j=1 #key to the ith row in new action_unique_values dataframe\n",
    "\n",
    "\n",
    "# for element in sessions_data_pivoted['user_id']:\n",
    "#     current_user = sessions_data[sessions_data.user_id == element] #filter dataframe for that user_id and assign filtered dataframe to current_user\n",
    "#     for element_action in action_detail_unique_values:\n",
    "#         running_sum = 0\n",
    "#         running_sum = current_user.action_detail[current_user.action_detail == action_detail_unique_values[i]].count() #assign the count of the latest action to running_sum \n",
    "#         i=i+1\n",
    "#         action_detail_unique_values_df.set_value(j, element_action, running_sum) #add the latest count of that action to action_unique_values dataframe\n",
    "#     j=j+1 #reindex so that we move to the next row when it looks at the next user\n",
    "#     i=0 #reindex so that we start at the beginning of action_unique_values when we look at next user\n",
    "    \n",
    "# writer = pd.ExcelWriter('action_detail_unique_values.xlsx')\n",
    "# action_detail_unique_values_df.to_excel(writer,'Sheet1')\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sessions_data[sessions_data.user_id == '0035hobuyj']\n",
    "\n",
    "# current_user.action_detail[current_user.action_detail == action_detail_unique_values[i]].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
